{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEigJ-mOGOk9"
      },
      "outputs": [],
      "source": [
        "# Copyright 2021 DeepMind Technologies Limited\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyGBRVPJxLzo"
      },
      "outputs": [],
      "source": [
        "# Install dependencies for Google Colab.\n",
        "# If you want to run this notebook on your own machine, you can skip this cell\n",
        "!pip install dm-haiku\n",
        "!pip install einops\n",
        "\n",
        "!mkdir /content/perceiver\n",
        "!touch /content/perceiver/__init__.py\n",
        "!wget -O /content/perceiver/io_processors.py https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/io_processors.py\n",
        "!wget -O /content/perceiver/perceiver.py https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/perceiver.py\n",
        "!wget -O /content/perceiver/position_encoding.py https://raw.githubusercontent.com/deepmind/deepmind-research/master/perceiver/position_encoding.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "VHzUTH5KqNEt"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "\n",
        "import functools\n",
        "import itertools\n",
        "import pickle\n",
        "\n",
        "import haiku as hk\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import cv2\n",
        "import imageio\n",
        "\n",
        "from perceiver import perceiver, io_processors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "uxeP5yit7hJg"
      },
      "outputs": [],
      "source": [
        "#@title Model construction\n",
        "\n",
        "FLOW_SCALE_FACTOR = 20\n",
        "# The network assumes images are of the following size\n",
        "TRAIN_SIZE = (368, 496)\n",
        "\n",
        "def optical_flow(images):\n",
        "  \"\"\"Perceiver IO model for optical flow.\n",
        "\n",
        "  Args:\n",
        "    images: Array of two stacked images, of shape [B, 2, H, W, C]\n",
        "  Returns:\n",
        "    Optical flow field, of shape [B, H, W, 2].\n",
        "  \"\"\"\n",
        "  input_preprocessor = io_processors.ImagePreprocessor(\n",
        "      position_encoding_type='fourier',\n",
        "      fourier_position_encoding_kwargs=dict(\n",
        "          num_bands=64,\n",
        "          max_resolution=TRAIN_SIZE,\n",
        "          sine_only=False,\n",
        "          concat_pos=True,\n",
        "      ),\n",
        "      n_extra_pos_mlp=0,\n",
        "      prep_type='patches',\n",
        "      spatial_downsample=1,\n",
        "      conv_after_patching=True,\n",
        "      temporal_downsample=2)\n",
        "\n",
        "  encoder = encoder = perceiver.PerceiverEncoder(\n",
        "      num_self_attends_per_block=24,\n",
        "      # Weights won't be shared if num_blocks is set to 1.\n",
        "      num_blocks=1,\n",
        "      z_index_dim=2048,\n",
        "      num_cross_attend_heads=1,\n",
        "      num_z_channels=512,\n",
        "      num_self_attend_heads=16,\n",
        "      cross_attend_widening_factor=1,\n",
        "      self_attend_widening_factor=1,\n",
        "      dropout_prob=0.0,\n",
        "      z_pos_enc_init_scale=0.02,\n",
        "      cross_attention_shape_for_attn='kv',\n",
        "      name='perceiver_encoder')\n",
        "\n",
        "  decoder = perceiver.FlowDecoder(\n",
        "      TRAIN_SIZE,\n",
        "      rescale_factor=100.0,\n",
        "      use_query_residual=False,\n",
        "      output_num_channels=2,\n",
        "      output_w_init=jnp.zeros,\n",
        "      # We query the decoder using the first frame features\n",
        "      # rather than a standard decoder position encoding.\n",
        "      position_encoding_type='fourier',\n",
        "      fourier_position_encoding_kwargs=dict(\n",
        "          concat_pos=True,\n",
        "          max_resolution=TRAIN_SIZE,\n",
        "          num_bands=64,\n",
        "          sine_only=False\n",
        "      )\n",
        "  )\n",
        "\n",
        "  model = perceiver.Perceiver(\n",
        "      input_preprocessor=input_preprocessor,\n",
        "      encoder=encoder,\n",
        "      decoder=decoder,\n",
        "      output_postprocessor=None)\n",
        "\n",
        "  return model(io_processors.patches_for_flow(images),\n",
        "               is_training=False) * FLOW_SCALE_FACTOR\n",
        "\n",
        "\n",
        "optical_flow = hk.transform(optical_flow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "dmvRv3o-6ASw"
      },
      "outputs": [],
      "source": [
        "#@title Function to compute flow between pairs of images\n",
        "\n",
        "# If you encounter GPU memory errors while running the function below,\n",
        "# you can run it on the CPU instead:\n",
        "# _apply_optical_flow_model = jax.jit(optical_flow.apply, backend=\"cpu\")\n",
        "_apply_optical_flow_model = jax.jit(optical_flow.apply)\n",
        "\n",
        "def compute_grid_indices(image_shape, patch_size=TRAIN_SIZE, min_overlap=20):\n",
        "  if min_overlap \u003e= TRAIN_SIZE[0] or min_overlap \u003e= TRAIN_SIZE[1]:\n",
        "    raise ValueError(\n",
        "        f\"Overlap should be less than size of patch (got {min_overlap}\"\n",
        "        f\"for patch size {patch_size}).\")\n",
        "  ys = list(range(0, image_shape[0], TRAIN_SIZE[0] - min_overlap))\n",
        "  xs = list(range(0, image_shape[1], TRAIN_SIZE[1] - min_overlap))\n",
        "  # Make sure the final patch is flush with the image boundary\n",
        "  ys[-1] = image_shape[0] - patch_size[0]\n",
        "  xs[-1] = image_shape[1] - patch_size[1]\n",
        "  return itertools.product(ys, xs)\n",
        "\n",
        "def compute_optical_flow(params, rng, img1, img2, grid_indices,\n",
        "                       patch_size=TRAIN_SIZE):\n",
        "  \"\"\"Function to compute optical flow between two images.\n",
        "\n",
        "  To compute the flow between images of arbitrary sizes, we divide the image\n",
        "  into patches, compute the flow for each patch, and stitch the flows together.\n",
        "\n",
        "  Args:\n",
        "    params: model parameters\n",
        "    rng: jax.random.PRNGKey, not used in this model\n",
        "    img1: first image\n",
        "    img2: second image\n",
        "    grid_indices: indices of the upper left corner for each patch.\n",
        "    patch_size: size of patch, should be TRAIN_SIZE.\n",
        "  \"\"\"\n",
        "  imgs = jnp.stack([img1, img2], axis=0)[None]\n",
        "  height = imgs.shape[-3]\n",
        "  width = imgs.shape[-2]\n",
        "\n",
        "  if height \u003c patch_size[0]:\n",
        "    raise ValueError(\n",
        "        f\"Height of image (shape: {imgs.shape}) must be at least {patch_size[0]}.\"\n",
        "        \"Please pad or resize your image to the minimum dimension.\"\n",
        "    )\n",
        "  if width \u003c patch_size[1]:\n",
        "    raise ValueError(\n",
        "        f\"Width of image (shape: {imgs.shape}) must be at least {patch_size[1]}.\"\n",
        "        \"Please pad or resize your image to the minimum dimension.\"\n",
        "    )\n",
        "\n",
        "  flows = 0\n",
        "  flow_count = 0\n",
        "\n",
        "  for y, x in grid_indices:\n",
        "    inp_piece = imgs[..., y : y + patch_size[0],\n",
        "                     x : x + patch_size[1], :]\n",
        "    flow_piece = _apply_optical_flow_model(params, rng, inp_piece)\n",
        "    weights_x, weights_y = jnp.meshgrid(\n",
        "        jnp.arange(patch_size[1]), jnp.arange(patch_size[0]))\n",
        "\n",
        "    weights_x = jnp.minimum(weights_x + 1, patch_size[1] - weights_x)\n",
        "    weights_y = jnp.minimum(weights_y + 1, patch_size[0] - weights_y)\n",
        "    weights = jnp.minimum(weights_x, weights_y)[jnp.newaxis, :, :,\n",
        "                                                jnp.newaxis]\n",
        "    padding = [(0, 0), (y, height - y - patch_size[0]),\n",
        "               (x, width - x - patch_size[1]), (0, 0)]\n",
        "    flows += jnp.pad(flow_piece * weights, padding)\n",
        "    flow_count += jnp.pad(weights, padding)\n",
        "\n",
        "  flows /= flow_count\n",
        "  return flows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EVRWatw4LXFx"
      },
      "outputs": [],
      "source": [
        "#@title Load parameters from checkpoint\n",
        "\n",
        "!wget -O optical_flow_checkpoint.pystate https://storage.googleapis.com/perceiver_io/optical_flow_checkpoint.pystate\n",
        "\n",
        "rng = jax.random.PRNGKey(42)\n",
        "with open(\"optical_flow_checkpoint.pystate\", \"rb\") as f:\n",
        "  params = pickle.loads(f.read())\n",
        "\n",
        "state = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAfLTtEXeE3-"
      },
      "outputs": [],
      "source": [
        "# Download two example frames from the Sintel dataset.\n",
        "# These files are obtained from the Sintel dataset test split,\n",
        "# downloaded from http://sintel.is.tue.mpg.de/downloads.\n",
        "# They correspond to MPI-Sintel-testing/test/clean/cave_3/frame_0001.png\n",
        "# and MPI-Sintel-testing/test/clean/cave_3/frame_0002.png.\n",
        "#\n",
        "# Citation for Sintel dataset:\n",
        "# D. J. Butler, J. Wulff, G. B. Stanley, and M. J. Black.\n",
        "# A naturalistic open source movie for optical flow evaluation.\n",
        "# European Conf. on Computer Vision (ECCV), 2012.\n",
        "# https://files.is.tue.mpg.de/black/papers/ButlerECCV2012.pdf\n",
        "#\n",
        "# The Sintel images are originally generated for the Durian Open Movie project\n",
        "# and are licensed under the Creative Commons Attribution 3.0 license (https://durian.blender.org/sharing/).\n",
        "# The images are copyrighted by the Blender Foundation (https://durian.blender.org).\n",
        "\n",
        "\n",
        "!wget -O sintel_frame1.png https://storage.googleapis.com/perceiver_io/sintel_frame1.png\n",
        "!wget -O sintel_frame2.png https://storage.googleapis.com/perceiver_io/sintel_frame2.png\n",
        "\n",
        "with open(\"sintel_frame1.png\", \"rb\") as f:\n",
        "  im1 = imageio.imread(f)\n",
        "with open(\"sintel_frame2.png\", \"rb\") as f:\n",
        "  im2 = imageio.imread(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Z7ZQJ2auy4Lt"
      },
      "outputs": [],
      "source": [
        "#@title Image Utility Functions\n",
        "\n",
        "def normalize(im):\n",
        "  return im / 255.0 * 2 - 1\n",
        "\n",
        "def visualize_flow(flow):\n",
        "  flow = np.array(flow)\n",
        "  # Use Hue, Saturation, Value colour model \n",
        "  hsv = np.zeros((flow.shape[0], flow.shape[1], 3), dtype=np.uint8)\n",
        "  hsv[..., 2] = 255\n",
        "\n",
        "  mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
        "  hsv[..., 0] = ang / np.pi / 2 * 180\n",
        "  hsv[..., 1] = np.clip(mag * 255 / 24, 0, 255)\n",
        "  bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "  plt.imshow(bgr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfWpBNZJLib4"
      },
      "outputs": [],
      "source": [
        "# Compute optical flow\n",
        "\n",
        "# Divide images into patches, compute flow between corresponding patches\n",
        "# of both images, and stitch the flows together\n",
        "grid_indices = compute_grid_indices(im1.shape)\n",
        "flow = compute_optical_flow(params, rng, normalize(im1), normalize(im2), grid_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bz7G04rmtHVI"
      },
      "outputs": [],
      "source": [
        "# Visualize the computed flow\n",
        "visualize_flow(flow[0])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Perceiver IO: Optical Flow Visualization.ipynb",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1bt4J3-jS7C-xZQrtx0AgAeKSBxOUoOPy",
          "timestamp": 1627577366926
        }
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
